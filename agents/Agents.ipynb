{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5170bf5b",
   "metadata": {},
   "source": [
    "# Agents - Make OpenAI Do Things For you"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9faa06",
   "metadata": {},
   "source": [
    "*[Source](https://langchain.readthedocs.io/en/latest/modules/agents/getting_started.html)*\n",
    "* **Agent** - Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\n",
    "\n",
    "Parameters when creating an agent:\n",
    "* **Tool:** A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an output.\n",
    "* **LLM:** The language model powering the agent.\n",
    "* **Agent:** The agent to use. This should be a string that references a support agent class. Because this notebook focuses on the simplest, highest level API, this only covers using the standard supported agents. If you want to implement a custom agent, see the documentation for custom agents (coming soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f247903",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T12:32:52.229350Z",
     "end_time": "2023-04-09T12:32:54.618352Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3670a",
   "metadata": {},
   "source": [
    "### List of Tools\n",
    "1. **python_repl -** A Python shell. Use this to execute python commands. Input should be a valid python command. If you expect output it should be printed out.\n",
    "2. **serpapi [Complete] -** A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
    "3. **wolfram-alpha [Complete] -** A wolfram alpha search engine. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query.\n",
    "4. **requests -** A portal to the internet. Use this when you need to get specific content from a site. Input should be a specific url, and the output will be all the text on that page.\n",
    "5. **terminal -** Executes commands in a terminal. Input should be valid commands, and the output will be any output from running that command.\n",
    "6. **pal-math -** A language model that is excellent at solving complex word math problems. Input should be a fully worded hard word math problem.\n",
    "7. **pal-colored-objects -** A language model that is wonderful at reasoning about position and the color attributes of objects. Input should be a fully worded hard reasoning problem. Make sure to include all information about the objects AND the final question you want to answer.\n",
    "8. **llm-math -** Useful for when you need to answer questions about math.\n",
    "9. **open-meteo-api -** Useful for when you want to get weather information from the OpenMeteo API. The input should be a question in natural language that this API can answer.\n",
    "10. **news-api -** Use this when you want to get information about the top headlines of current news stories. The input should be a question in natural language that this API can answer.\n",
    "11. **tmdb-api -** Useful for when you want to get information from The Movie Database. The input should be a question in natural language that this API can answer.\n",
    "12. **google-search -** A wrapper around Google Search. Useful for when you need to answer questions about current events. Input should be a search query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83032dcf",
   "metadata": {},
   "source": [
    "### 2. SERP API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c90ba74",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T12:32:54.626046Z",
     "end_time": "2023-04-09T12:32:54.631792Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "# import os\n",
    "# os.environ['OPENAI_API_KEY'] = \"...\"\n",
    "# os.environ['SERPAPI_API_KEY'] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f2fd44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mOpenAI\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:341\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26a0dd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SerpAPIWrapper\n__root__\n  Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass  `serpapi_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m tool_names \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserpapi\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m tools \u001B[38;5;241m=\u001B[39m \u001B[43mload_tools\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtool_names\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/load_tools.py:300\u001B[0m, in \u001B[0;36mload_tools\u001B[0;34m(tool_names, llm, callback_manager, **kwargs)\u001B[0m\n\u001B[1;32m    298\u001B[0m _get_tool_func, extra_keys \u001B[38;5;241m=\u001B[39m _EXTRA_OPTIONAL_TOOLS[name]\n\u001B[1;32m    299\u001B[0m sub_kwargs \u001B[38;5;241m=\u001B[39m {k: kwargs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m extra_keys \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs}\n\u001B[0;32m--> 300\u001B[0m tool \u001B[38;5;241m=\u001B[39m \u001B[43m_get_tool_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msub_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callback_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    302\u001B[0m     tool\u001B[38;5;241m.\u001B[39mcallback_manager \u001B[38;5;241m=\u001B[39m callback_manager\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/langchain/agents/load_tools.py:194\u001B[0m, in \u001B[0;36m_get_serpapi\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_serpapi\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseTool:\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Tool(\n\u001B[1;32m    192\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSearch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    193\u001B[0m         description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA search engine. Useful for when you need to answer questions about current events. Input should be a search query.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m--> 194\u001B[0m         func\u001B[38;5;241m=\u001B[39m\u001B[43mSerpAPIWrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mrun,\n\u001B[1;32m    195\u001B[0m         coroutine\u001B[38;5;241m=\u001B[39mSerpAPIWrapper(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\u001B[38;5;241m.\u001B[39marun,\n\u001B[1;32m    196\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:341\u001B[0m, in \u001B[0;36mpydantic.main.BaseModel.__init__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mValidationError\u001B[0m: 1 validation error for SerpAPIWrapper\n__root__\n  Did not find serpapi_api_key, please add an environment variable `SERPAPI_API_KEY` which contains it, or pass  `serpapi_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "tool_names = [\"serpapi\"]\n",
    "tools = load_tools(tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8a35518",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "829a2d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is a platform that provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications. Data Augmented Reality (DAR) is also supported.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4cc45f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Luke Voiles is the CEO of Pipe.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input should be a search query.\n",
    "agent.run(\"who is the ceo of pipe?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869cabc",
   "metadata": {},
   "source": [
    "### 3. Wolfram Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0fd02098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "# import os\n",
    "# pip install wolframalpha\n",
    "# os.environ['OPENAI_API_KEY'] = \"...\"\n",
    "# os.environ['WOLFRAM_ALPHA_APPID'] = \"..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a96dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ba4200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [\"wolfram-alpha\"]\n",
    "tools = load_tools(tool_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4716e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89e0d255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The asthenosphere is the lower layer of the crust.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input should be a search query.\n",
    "\n",
    "agent.run(\"What is the asthenosphere?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c98c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
